{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd, xgboost, numpy as np, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = pd.read_csv(\"./news_scraping_results_and_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = news_scraping_results.dropna(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = pd.read_csv(\"./tickers_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_ticker_news = news_scraping_results[news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ticker_news = news_scraping_results[~news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2571, 2572, 2573])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_ticker_news.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_news = active_ticker_news[active_ticker_news['sentiment'] == 'positive'].reset_index()\n",
    "balanced_news = balanced_news.append(active_ticker_news[active_ticker_news['sentiment'] == 'negative'].reset_index()[:237], ignore_index=True)\n",
    "balanced_news = balanced_news.append(active_ticker_news[active_ticker_news['sentiment'] == 'neutral'].reset_index()[:237], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_balanced_news = balanced_news.append(suspended_ticker_news.reset_index(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dataset with suspended and balanced active stock\n",
    "X, y = suspended_balanced_news[['CONTENT']].values.flatten().astype(str), suspended_balanced_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset without suspended stock \n",
    "Xb, yb = balanced_news[['CONTENT']].values.flatten().astype(str), balanced_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = suspended_ticker_news[['CONTENT']].values.flatten().astype(str), suspended_ticker_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(Xb, yb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ys = encoder.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode_y.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(encode_y, columns=['sentiment']).to_csv('balanced_encoded_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = count_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_count_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_X)\n",
    "xtest_count =  count_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstest_count =  count_vect.transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=None)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_X)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstest_tfidf =  tfidf_vect.transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode document\n",
    "vector = tfidf_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n",
    "#print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_tfidf_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, feature_vector_suspended, is_neural_net=False, classifier_name=None, feature_vector_name=None):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    \n",
    "    # predict the labels on the suspension stock dataset\n",
    "    suspended_prediction = classifier.predict(feature_vector_suspended)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, predictions)\n",
    "    precision = metrics.precision_score(test_y, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(test_y, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(test_y, predictions, average=\"macro\")\n",
    "    \n",
    "    \n",
    "    suspended_accuracy = metrics.accuracy_score(test_ys, suspended_prediction)\n",
    "    suspended_precision = metrics.precision_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    suspended_recall = metrics.recall_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    suspended_f1 = metrics.f1_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    \n",
    "    df = pd.DataFrame([[classifier_name, feature_vector_name, accuracy,precision,recall,f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1]], columns=['classifier','feature vector','accuracy','precision','recall','f1', 'suspended_accuracy', 'suspended_precision', 'suspended_recall', 'suspended_f1'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1', 'suspended_accuracy', 'suspended_precision', 'suspended_recall', 'suspended_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "scores = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count, xstest_count, classifier_name='Naive Bayes', feature_vector_name='Count')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on TF-IDF Vectors\n",
    "scores = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf, classifier_name='Naive Bayes', feature_vector_name='TF-IDF')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on Count Vectors\n",
    "scores = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count, xstest_count, classifier_name='Logistic Regression', feature_vector_name='Count')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression on TF-IDF Vectors\n",
    "scores = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf, classifier_name='Logistic Regression', feature_vector_name='TF-IDF')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Count Vectors\n",
    "scores = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xtest_count, xstest_count, classifier_name='Random Forest', feature_vector_name='Count')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on TF-IDF Vectors\n",
    "scores = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf, classifier_name='Random Forest', feature_vector_name='TF-IDF')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Boosting Gradient on Count Vectors\n",
    "scores = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xtest_count.tocsc(), xstest_count.tocsc(), classifier_name='Extreme Boosting Gradient', feature_vector_name='Count')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Boosting Gradient on TF-IDF Vectors\n",
    "scores = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc(), xstest_tfidf.tocsc(), classifier_name='Extreme Gradient Boosting', feature_vector_name='TF-IDF')\n",
    "metrics_df = metrics_df.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>feature vector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>suspended_accuracy</th>\n",
       "      <th>suspended_precision</th>\n",
       "      <th>suspended_recall</th>\n",
       "      <th>suspended_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.554663</td>\n",
       "      <td>0.552751</td>\n",
       "      <td>0.275676</td>\n",
       "      <td>0.366836</td>\n",
       "      <td>0.372062</td>\n",
       "      <td>0.264946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.625708</td>\n",
       "      <td>0.604181</td>\n",
       "      <td>0.559187</td>\n",
       "      <td>0.372973</td>\n",
       "      <td>0.354581</td>\n",
       "      <td>0.367763</td>\n",
       "      <td>0.295100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.494652</td>\n",
       "      <td>0.499886</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.327027</td>\n",
       "      <td>0.363528</td>\n",
       "      <td>0.364584</td>\n",
       "      <td>0.307035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.563874</td>\n",
       "      <td>0.565751</td>\n",
       "      <td>0.555093</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.324936</td>\n",
       "      <td>0.247383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.500369</td>\n",
       "      <td>0.515208</td>\n",
       "      <td>0.484711</td>\n",
       "      <td>0.332432</td>\n",
       "      <td>0.350679</td>\n",
       "      <td>0.363959</td>\n",
       "      <td>0.318469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.504972</td>\n",
       "      <td>0.498196</td>\n",
       "      <td>0.485387</td>\n",
       "      <td>0.345946</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.359918</td>\n",
       "      <td>0.328673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Extreme Boosting Gradient</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.573721</td>\n",
       "      <td>0.587529</td>\n",
       "      <td>0.565458</td>\n",
       "      <td>0.359459</td>\n",
       "      <td>0.383909</td>\n",
       "      <td>0.390571</td>\n",
       "      <td>0.337581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.549441</td>\n",
       "      <td>0.565448</td>\n",
       "      <td>0.544438</td>\n",
       "      <td>0.375676</td>\n",
       "      <td>0.411842</td>\n",
       "      <td>0.397664</td>\n",
       "      <td>0.350537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  classifier feature vector  accuracy  precision    recall  \\\n",
       "0                Naive Bayes          Count  0.552448   0.552200  0.554663   \n",
       "1                Naive Bayes         TF-IDF  0.573427   0.625708  0.604181   \n",
       "2        Logistic Regression          Count  0.496503   0.494652  0.499886   \n",
       "3        Logistic Regression         TF-IDF  0.552448   0.563874  0.565751   \n",
       "4              Random Forest          Count  0.489510   0.500369  0.515208   \n",
       "5              Random Forest         TF-IDF  0.482517   0.504972  0.498196   \n",
       "6  Extreme Boosting Gradient          Count  0.566434   0.573721  0.587529   \n",
       "7  Extreme Gradient Boosting         TF-IDF  0.545455   0.549441  0.565448   \n",
       "\n",
       "         f1  suspended_accuracy  suspended_precision  suspended_recall  \\\n",
       "0  0.552751            0.275676             0.366836          0.372062   \n",
       "1  0.559187            0.372973             0.354581          0.367763   \n",
       "2  0.495960            0.327027             0.363528          0.364584   \n",
       "3  0.555093            0.281081             0.322197          0.324936   \n",
       "4  0.484711            0.332432             0.350679          0.363959   \n",
       "5  0.485387            0.345946             0.370787          0.359918   \n",
       "6  0.565458            0.359459             0.383909          0.390571   \n",
       "7  0.544438            0.375676             0.411842          0.397664   \n",
       "\n",
       "   suspended_f1  \n",
       "0      0.264946  \n",
       "1      0.295100  \n",
       "2      0.307035  \n",
       "3      0.247383  \n",
       "4      0.318469  \n",
       "5      0.328673  \n",
       "6      0.337581  \n",
       "7      0.350537  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('metrics_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs] *",
   "language": "python",
   "name": "conda-env-cs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
