{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd, xgboost, numpy as np, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = pd.read_csv(\"./news_scraping_results_and_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = news_scraping_results.dropna(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = pd.read_csv(\"./tickers_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_ticker_news = news_scraping_results[news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ticker_news = news_scraping_results[~news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_ticker_news.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISH_TIME</th>\n",
       "      <th>SCRAPED_TIME</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>BIO</td>\n",
       "      <td>GlobeNewswire</td>\n",
       "      <td>http://www.globenewswire.com/news-release/2019...</td>\n",
       "      <td>2019-10-09 07:49:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Global Apoptosis Industry - GlobeNewswire</td>\n",
       "      <td>new york oct 09 2019 globe newswire reportlink...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>ADNT</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/adient-aided-tu...</td>\n",
       "      <td>2019-10-09 14:04:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Adient Aided by Turnaround Plans Amid Industry...</td>\n",
       "      <td>adient plcs adnt share have rally 31 so far th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>ADNT</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/adient-discuss-...</td>\n",
       "      <td>2019-10-04 15:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Adient to discuss Q4 fiscal 2019 financial res...</td>\n",
       "      <td>plymouth mich oct 4 2019 prnewswire adient adn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>AOSL</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/alpha-omega-sem...</td>\n",
       "      <td>2019-08-07 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Alpha and Omega Semiconductor (AOSL) Tops Q4 E...</td>\n",
       "      <td>alpha and omega semiconductor aosl come out wi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>AOSL</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/alpha-omega-sem...</td>\n",
       "      <td>2019-05-20 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Alpha and Omega Semiconductor to Present at th...</td>\n",
       "      <td>sunnyvale calif business wire alpha and omega ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2412</td>\n",
       "      <td>MLCO</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-crown-resor...</td>\n",
       "      <td>2019-08-08 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Australian gaming watchdog to review Melco's $...</td>\n",
       "      <td>file photo a logo on crown towers as part of c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2413</td>\n",
       "      <td>CCL</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-cuba-usa-tr...</td>\n",
       "      <td>2018-12-11 08:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>Americans venture back to Cuba as hurricane me...</td>\n",
       "      <td>havana reuters u s travel to cuba be bounce ba...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2458</td>\n",
       "      <td>BYND</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-mcdonald-s-...</td>\n",
       "      <td>2019-09-26 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>McDonald's joins Beyond Meat bandwagon with Ca...</td>\n",
       "      <td>reuters mcdonalds corp mcd n will test a new p...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2472</td>\n",
       "      <td>NRG</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-new-york-co...</td>\n",
       "      <td>2019-05-10 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>New York adopts rules to phase out coal power ...</td>\n",
       "      <td>new york reuters new york environmental regula...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2514</td>\n",
       "      <td>W</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-usa-compani...</td>\n",
       "      <td>2019-06-28 07:00:00+00:00</td>\n",
       "      <td>2019-10-09-16-24</td>\n",
       "      <td>When controversies hit, wait-and-see no longer...</td>\n",
       "      <td>new york reuters when bank of america corp bac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SYMBOL      SITE_NAME                                                URL  \\\n",
       "14      BIO  GlobeNewswire  http://www.globenewswire.com/news-release/2019...   \n",
       "54     ADNT  Yahoo Finance  https://finance.yahoo.com/news/adient-aided-tu...   \n",
       "56     ADNT  Yahoo Finance  https://finance.yahoo.com/news/adient-discuss-...   \n",
       "67     AOSL  Yahoo Finance  https://finance.yahoo.com/news/alpha-omega-sem...   \n",
       "70     AOSL  Yahoo Finance  https://finance.yahoo.com/news/alpha-omega-sem...   \n",
       "...     ...            ...                                                ...   \n",
       "2412   MLCO        Reuters  https://www.reuters.com/article/us-crown-resor...   \n",
       "2413    CCL        Reuters  https://www.reuters.com/article/us-cuba-usa-tr...   \n",
       "2458   BYND        Reuters  https://www.reuters.com/article/us-mcdonald-s-...   \n",
       "2472    NRG        Reuters  https://www.reuters.com/article/us-new-york-co...   \n",
       "2514      W        Reuters  https://www.reuters.com/article/us-usa-compani...   \n",
       "\n",
       "                   PUBLISH_TIME      SCRAPED_TIME  \\\n",
       "14    2019-10-09 07:49:00+00:00  2019-10-09-16-24   \n",
       "54    2019-10-09 14:04:00+00:00  2019-10-09-16-24   \n",
       "56    2019-10-04 15:00:00+00:00  2019-10-09-16-24   \n",
       "67    2019-08-07 07:00:00+00:00  2019-10-09-16-24   \n",
       "70    2019-05-20 07:00:00+00:00  2019-10-09-16-24   \n",
       "...                         ...               ...   \n",
       "2412  2019-08-08 07:00:00+00:00  2019-10-09-16-24   \n",
       "2413  2018-12-11 08:00:00+00:00  2019-10-09-16-24   \n",
       "2458  2019-09-26 07:00:00+00:00  2019-10-09-16-24   \n",
       "2472  2019-05-10 07:00:00+00:00  2019-10-09-16-24   \n",
       "2514  2019-06-28 07:00:00+00:00  2019-10-09-16-24   \n",
       "\n",
       "                                                  TITLE  \\\n",
       "14            Global Apoptosis Industry - GlobeNewswire   \n",
       "54    Adient Aided by Turnaround Plans Amid Industry...   \n",
       "56    Adient to discuss Q4 fiscal 2019 financial res...   \n",
       "67    Alpha and Omega Semiconductor (AOSL) Tops Q4 E...   \n",
       "70    Alpha and Omega Semiconductor to Present at th...   \n",
       "...                                                 ...   \n",
       "2412  Australian gaming watchdog to review Melco's $...   \n",
       "2413  Americans venture back to Cuba as hurricane me...   \n",
       "2458  McDonald's joins Beyond Meat bandwagon with Ca...   \n",
       "2472  New York adopts rules to phase out coal power ...   \n",
       "2514  When controversies hit, wait-and-see no longer...   \n",
       "\n",
       "                                                CONTENT sentiment  \n",
       "14    new york oct 09 2019 globe newswire reportlink...  negative  \n",
       "54    adient plcs adnt share have rally 31 so far th...  negative  \n",
       "56    plymouth mich oct 4 2019 prnewswire adient adn...  negative  \n",
       "67    alpha and omega semiconductor aosl come out wi...  negative  \n",
       "70    sunnyvale calif business wire alpha and omega ...  negative  \n",
       "...                                                 ...       ...  \n",
       "2412  file photo a logo on crown towers as part of c...  negative  \n",
       "2413  havana reuters u s travel to cuba be bounce ba...  negative  \n",
       "2458  reuters mcdonalds corp mcd n will test a new p...  negative  \n",
       "2472  new york reuters new york environmental regula...  negative  \n",
       "2514  new york reuters when bank of america corp bac...  negative  \n",
       "\n",
       "[238 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_ticker_news[active_ticker_news['sentiment']=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_news = active_ticker_news[active_ticker_news['sentiment'] == 'positive'].reset_index()\n",
    "balanced_news = balanced_news.append(active_ticker_news[active_ticker_news['sentiment'] == 'negative'].reset_index()[:237], ignore_index=True)\n",
    "balanced_news = balanced_news.append(active_ticker_news[active_ticker_news['sentiment'] == 'neutral'].reset_index()[:237], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_balanced_news = balanced_news.append(suspended_ticker_news.reset_index(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole dataset with suspended and balanced active stock\n",
    "X, y = suspended_balanced_news[['CONTENT']].values.flatten().astype(str), suspended_balanced_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset without suspended stock \n",
    "Xb, yb = balanced_news[['CONTENT']].values.flatten().astype(str), balanced_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = suspended_ticker_news[['CONTENT']].values.flatten().astype(str), suspended_ticker_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(Xb, yb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ys = encoder.fit_transform(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode_y.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(encode_y, columns=['sentiment']).to_csv('balanced_encoded_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = count_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_count_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_X)\n",
    "xtest_count =  count_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstest_count =  count_vect.transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=None)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_X)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstest_tfidf =  tfidf_vect.transform(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode document\n",
    "vector = tfidf_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n",
    "#print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_tfidf_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, feature_vector_suspended, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    \n",
    "    # predict the labels on the suspension stock dataset\n",
    "    suspended_prediction = classifier.predict(feature_vector_suspended)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, predictions)\n",
    "    precision = metrics.precision_score(test_y, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(test_y, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(test_y, predictions, average=\"macro\")\n",
    "    \n",
    "    suspended_accuracy = metrics.accuracy_score(test_ys, suspended_prediction)\n",
    "    suspended_precision = metrics.precision_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    suspended_recall = metrics.recall_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    suspended_f1 = metrics.f1_score(test_ys, suspended_prediction, average=\"macro\")\n",
    "    \n",
    "    return accuracy,precision,recall,f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation_df = pd.DataFrame(columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count, xstest_count)\n",
    "#metrics = pd.DataFrame([['Naive Bayes', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Naive Bayes, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, Count Vectors: \n",
      " accuracy: 0.5524475524475524\n",
      " precision: 0.5510528923572401\n",
      " recall: 0.555023923444976\n",
      " f1:0.5523099816045086\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUSPENDED Naive Bayes, Count Vectors: \n",
      " accuracy: 0.27837837837837837\n",
      " precision: 0.3681610291779784\n",
      " recall: 0.37493574641250804\n",
      " f1:(0.5454545454545454, 0.593192195931922, 0.574884180147338, 0.5318657127132637, 0.3891891891891892, 0.38559264258736586, 0.38795423716713073, 0.3089963515903971)\n"
     ]
    }
   ],
   "source": [
    "print(\"SUSPENDED Naive Bayes, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(suspended_accuracy, suspended_precision, suspended_recall, suspended_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = pd.DataFrame([['Naive Bayes', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "nb_count = np.array(['Naive Bayes', 'Count', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf)\n",
    "#metrics = pd.DataFrame([['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Naive Bayes, TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = pd.DataFrame([['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "nb_tfidf = np.array(['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count, xstest_count)\n",
    "#metrics = pd.DataFrame([['Logisitic Regression', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"linear Classifier, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_count = np.array(['Logistic Regression', 'Count', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf)\n",
    "#metrics = pd.DataFrame([['Logisitic Regression', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"linear Classifier, TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = np.array(['Logistic Regression', 'TF-IDF', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Count Vectors\n",
    "accuracy,precision,recall,f1, \n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xtest_count, xstest_count)\n",
    "#metrics = pd.DataFrame([['Random Forest', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Random Forest, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_count = np.array(['Random Forest', 'Count', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xtest_tfidf, xstest_tfidf)\n",
    "#metrics = pd.DataFrame([['Random Forest', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Random Forest, WordLevel TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf = np.array(['Random Forest', 'TF-IDF', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xtest_count.tocsc(), xstest_count.tocsc())\n",
    "#metrics = pd.DataFrame([['Extreme Gradient Boosting', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Xgb, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_count = np.array(['Extreme Gradient Boosting', 'Count', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1,\n",
    "suspended_accuracy, \n",
    "suspended_precision, \n",
    "suspended_recall,\n",
    "suspended_f1 = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc(), xstest_tfidf.tocsc())\n",
    "#metrics = pd.DataFrame([['Extreme Gradient Boosting', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Xgb, WordLevel TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tfidf = np.array(['Extreme Gradient Boosting', 'TF-IDF', accuracy, precision, recall, f1, suspended_accuracy, suspended_precision, suspended_recall, suspended_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = np.array([nb_count, nb_tfidf, lr_count, lr_tfidf, rf_count, rf_tfidf, xgb_count, xgb_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_all, columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1', 'suspended accuracy', 'suspended precision', 'suspended recall', 'suspended f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall \n",
    "#remove sus stocks from list, then do senti anaysis on this 80 20 \n",
    "#the second accuracy test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>feature vector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  classifier feature vector            accuracy  \\\n",
       "0                Naive Bayes          Count  0.4965034965034965   \n",
       "1                Naive Bayes         TF-IDF  0.4965034965034965   \n",
       "2        Logistic Regression          Count  0.4965034965034965   \n",
       "3        Logistic Regression         TF-IDF  0.4965034965034965   \n",
       "4              Random Forest          Count  0.4965034965034965   \n",
       "5              Random Forest         TF-IDF  0.4965034965034965   \n",
       "6  Extreme Gradient Boosting          Count  0.4965034965034965   \n",
       "7  Extreme Gradient Boosting         TF-IDF  0.4965034965034965   \n",
       "\n",
       "            precision              recall                   f1  \n",
       "0  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "1  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "2  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "3  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "4  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "5  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "6  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "7  0.4946524064171123  0.4998860788334472  0.49595959595959593  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_all, columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('metrics_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>feature vector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>suspended accuracy</th>\n",
       "      <th>suspended precision</th>\n",
       "      <th>suspended recall</th>\n",
       "      <th>suspended f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5384615384615384, 0.5411802232854864, 0.557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5454545454545454, 0.593192195931922, 0.5748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.4965034965034965, 0.4946524064171123, 0.499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5594405594405595, 0.5727339181286549, 0.573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5104895104895105, 0.5157828282828283, 0.527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.48951048951048953, 0.5198160535117057, 0.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5664335664335665, 0.573721340388007, 0.5875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.55231</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.374936</td>\n",
       "      <td>(0.5384615384615384, 0.5411802232854864, 0.557...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  classifier feature vector  accuracy precision    recall  \\\n",
       "0                Naive Bayes          Count  0.552448  0.551053  0.555024   \n",
       "1                Naive Bayes         TF-IDF  0.552448  0.551053  0.555024   \n",
       "2        Logistic Regression          Count  0.552448  0.551053  0.555024   \n",
       "3        Logistic Regression         TF-IDF  0.552448  0.551053  0.555024   \n",
       "4              Random Forest          Count  0.552448  0.551053  0.555024   \n",
       "5              Random Forest         TF-IDF  0.552448  0.551053  0.555024   \n",
       "6  Extreme Gradient Boosting          Count  0.552448  0.551053  0.555024   \n",
       "7  Extreme Gradient Boosting         TF-IDF  0.552448  0.551053  0.555024   \n",
       "\n",
       "        f1 suspended accuracy suspended precision suspended recall  \\\n",
       "0  0.55231           0.278378            0.368161         0.374936   \n",
       "1  0.55231           0.278378            0.368161         0.374936   \n",
       "2  0.55231           0.278378            0.368161         0.374936   \n",
       "3  0.55231           0.278378            0.368161         0.374936   \n",
       "4  0.55231           0.278378            0.368161         0.374936   \n",
       "5  0.55231           0.278378            0.368161         0.374936   \n",
       "6  0.55231           0.278378            0.368161         0.374936   \n",
       "7  0.55231           0.278378            0.368161         0.374936   \n",
       "\n",
       "                                        suspended f1  \n",
       "0  (0.5384615384615384, 0.5411802232854864, 0.557...  \n",
       "1  (0.5454545454545454, 0.593192195931922, 0.5748...  \n",
       "2  (0.4965034965034965, 0.4946524064171123, 0.499...  \n",
       "3  (0.5594405594405595, 0.5727339181286549, 0.573...  \n",
       "4  (0.5104895104895105, 0.5157828282828283, 0.527...  \n",
       "5  (0.48951048951048953, 0.5198160535117057, 0.50...  \n",
       "6  (0.5664335664335665, 0.573721340388007, 0.5875...  \n",
       "7  (0.5384615384615384, 0.5411802232854864, 0.557...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs] *",
   "language": "python",
   "name": "conda-env-cs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
