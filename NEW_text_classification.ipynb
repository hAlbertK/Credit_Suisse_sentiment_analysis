{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd, xgboost, numpy as np, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = pd.read_csv(\"./news_scraping_results_and_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_scraping_results = news_scraping_results.dropna(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = pd.read_csv(\"./tickers_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspended_ticker_news = news_scraping_results[news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ticker_news = news_scraping_results[~news_scraping_results['SYMBOL'].isin(tickers_list['Symbol'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_ticker_news.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_news = news_scraping_results[news_scraping_results['sentiment'] == 'positive'].reset_index()\n",
    "balanced_news = balanced_news.append(news_scraping_results[news_scraping_results['sentiment'] == 'negative'].reset_index()[:237], ignore_index=True)\n",
    "balanced_news = balanced_news.append(news_scraping_results[news_scraping_results['sentiment'] == 'neutral'].reset_index()[:237], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = balanced_news[['CONTENT']].values.flatten().astype(str), balanced_news[['sentiment']].values.flatten().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcome to morningstar co uk -pron- have be redirect here from hemscott com as -pron- be merge -pron- website to provide -pron- with a one stop shop for all -pron- investment research need to search for a security type the name or ticker in the search box at the top of the page and select from the dropdown result register hemscott user can log in to morningstar use the same login detail similarly if -pron- be a hemscott premium user -pron- now have a morningstar premium account which -pron- can access use the same login detail'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset without suspended stock \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode_y.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(encode_y, columns=['sentiment']).to_csv('balanced_encoded_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = count_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_count_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_X)\n",
    "xtest_count =  count_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=None)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_X)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode document\n",
    "vector = tfidf_vect.transform(X)\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n",
    "#print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(vector.toarray()).to_csv('balanced_tfidf_vectorized_CONTENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, predictions)\n",
    "    precision = metrics.precision_score(test_y, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(test_y, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(test_y, predictions, average=\"macro\")\n",
    "    \n",
    "    return accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation_df = pd.DataFrame(columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, Count Vectors: \n",
      " accuracy: 0.5524475524475524\n",
      " precision: 0.5510528923572401\n",
      " recall: 0.555023923444976\n",
      " f1:0.5523099816045086\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy,precision,recall,f1 = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count)\n",
    "#metrics = pd.DataFrame([['Naive Bayes', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Naive Bayes, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = pd.DataFrame([['Naive Bayes', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "nb_count = np.array(['Naive Bayes', 'Count', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, TF-IDF: \n",
      " accuracy: 0.5454545454545454\n",
      " precision: 0.593192195931922\n",
      " recall: 0.574884180147338\n",
      " f1:0.5318657127132637\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1 = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "#metrics = pd.DataFrame([['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Naive Bayes, TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = pd.DataFrame([['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "nb_tfidf = np.array(['Naive Bayes', 'TF-IDF', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear Classifier, Count Vectors: \n",
      " accuracy: 0.4965034965034965\n",
      " precision: 0.4946524064171123\n",
      " recall: 0.4998860788334472\n",
      " f1:0.49595959595959593\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy,precision,recall,f1 = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count)\n",
    "#metrics = pd.DataFrame([['Logisitic Regression', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"linear Classifier, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_count = np.array(['Logistic Regression', 'Count', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear Classifier, TF-IDF: \n",
      " accuracy: 0.5594405594405595\n",
      " precision: 0.5727339181286549\n",
      " recall: 0.5733272575377839\n",
      " f1:0.5618705730222144\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1 = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "#metrics = pd.DataFrame([['Logisitic Regression', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"linear Classifier, TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = np.array(['Logistic Regression', 'TF-IDF', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, Count Vectors: \n",
      " accuracy: 0.5524475524475524\n",
      " precision: 0.5584074449322677\n",
      " recall: 0.5657514999620262\n",
      " f1:0.5556466599805284\n",
      "Random Forest, WordLevel TF-IDF: \n",
      " accuracy: 0.4755244755244755\n",
      " precision: 0.49490183491146417\n",
      " recall: 0.49443684970000756\n",
      " f1:0.47485808692705245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/albert/anaconda3/envs/cs/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Count Vectors\n",
    "accuracy,precision,recall,f1 = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xtest_count)\n",
    "#metrics = pd.DataFrame([['Random Forest', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Random Forest, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_count = np.array(['Random Forest', 'Count', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1 = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "#metrics = pd.DataFrame([['Random Forest', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Random Forest, WordLevel TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf = np.array(['Random Forest', 'TF-IDF', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors: \n",
      " accuracy: 0.5664335664335665\n",
      " precision: 0.573721340388007\n",
      " recall: 0.5875294296346928\n",
      " f1:0.5654577048210588\n",
      "Xgb, WordLevel TF-IDF: \n",
      " accuracy: 0.5384615384615384\n",
      " precision: 0.5411802232854864\n",
      " recall: 0.5575112022480443\n",
      " f1:0.5393315304070453\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy,precision,recall,f1 = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xtest_count.tocsc())\n",
    "#metrics = pd.DataFrame([['Extreme Gradient Boosting', 'Count', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Xgb, Count Vectors: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1 = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc())\n",
    "#metrics = pd.DataFrame([['Extreme Gradient Boosting', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Xgb, WordLevel TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_count = np.array(['Extreme Gradient Boosting', 'Count', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy,precision,recall,f1 = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc())\n",
    "#metrics = pd.DataFrame([['Extreme Gradient Boosting', 'TF-IDF', accuracy, precision, recall, f1]], columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "#evaluation_df = evaluation_df.append(metrics)\n",
    "#print(\"Xgb, WordLevel TF-IDF: \\n accuracy: %s\\n precision: %s\\n recall: %s\\n f1:%s\"%(accuracy,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tfidf = np.array(['Extreme Gradient Boosting', 'TF-IDF', accuracy, precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = np.array([nb_count, nb_tfidf, lr_count, lr_tfidf, rf_count, rf_tfidf, xgb_count, xgb_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_all, columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('metrics_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall \n",
    "#remove sus stocks from list, then do senti anaysis on this 80 20 \n",
    "#the second accuracy test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>feature vector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>Count</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.4965034965034965</td>\n",
       "      <td>0.4946524064171123</td>\n",
       "      <td>0.4998860788334472</td>\n",
       "      <td>0.49595959595959593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  classifier feature vector            accuracy  \\\n",
       "0                Naive Bayes          Count  0.4965034965034965   \n",
       "1                Naive Bayes         TF-IDF  0.4965034965034965   \n",
       "2        Logistic Regression          Count  0.4965034965034965   \n",
       "3        Logistic Regression         TF-IDF  0.4965034965034965   \n",
       "4              Random Forest          Count  0.4965034965034965   \n",
       "5              Random Forest         TF-IDF  0.4965034965034965   \n",
       "6  Extreme Gradient Boosting          Count  0.4965034965034965   \n",
       "7  Extreme Gradient Boosting         TF-IDF  0.4965034965034965   \n",
       "\n",
       "            precision              recall                   f1  \n",
       "0  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "1  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "2  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "3  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "4  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "5  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "6  0.4946524064171123  0.4998860788334472  0.49595959595959593  \n",
       "7  0.4946524064171123  0.4998860788334472  0.49595959595959593  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_all, columns=['classifier', 'feature vector', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs] *",
   "language": "python",
   "name": "conda-env-cs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
