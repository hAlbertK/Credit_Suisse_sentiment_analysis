{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ew6yKCmSv-lD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "ytSINX1lwhpu",
    "outputId": "1cfa9fee-54b4-4838-da62-618f2c4e79ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1269\n",
       "negative    1269\n",
       "neutral     1269\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/data/CS/SA/threshold4_balanced_training_set.csv', usecols=['CONTENT','sentiment'])\n",
    "df.head(10)\n",
    "df['label']=df['sentiment']\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "k2fsZaRjwlTW",
    "outputId": "80c0d3b7-0e9f-40b2-9676-c44f438b7834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1269\n",
       "1    1269\n",
       "0    1269\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, item in enumerate (df['label']):\n",
    "  if item=='positive':\n",
    "    df['label'][i]=2\n",
    "  if item=='neutral':\n",
    "    df['label'][i]=1\n",
    "  if item=='negative':\n",
    "    df['label'][i]=0\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvvLbvEuwwI3"
   },
   "outputs": [],
   "source": [
    "tdf = pd.read_csv('C:/data/CS/SA/test.csv')\n",
    "len(tdf)\n",
    "x = df['CONTENT']\n",
    "y = df['label']\n",
    "x_test=tdf['CONTENT']\n",
    "y_test=tdf['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tA-tdBBCwz9J",
    "outputId": "278f71d0-3ba3-4e2d-d2be-012ea02e9307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390    the stock market get hit with a double whammy ...\n",
      "1297    this aerial photo take on january 2 2017 show ...\n",
      "3320    doylestown pa jan 17 2019 globe newswire proph...\n",
      "3466    new york business wire long term shareholder h...\n",
      "1987    -pron- seem that the mass and most of the fina...\n",
      "1711    investor in goodyear tire rubber co symbol gt ...\n",
      "785     dublin oct 2 2019 prnewswire the passenger sec...\n",
      "642     chicago july 8 2019 prnewswire the chicago qua...\n",
      "747     this news release constitute a designate news ...\n",
      "1792    oil price rise for four consecutive trading da...\n",
      "855     herndon va oct 07 2019 globe newswire skybitz ...\n",
      "309     new york oct 28 2019 globe newswire vornado re...\n",
      "684     tempe ariz april 24 2019 prnewswire benchmark ...\n",
      "1429    the late 13f reporting period have come and go...\n",
      "338     for immediate release chicago il october 17 20...\n",
      "758     san diego sept 12 2019 prnewswire l attitude a...\n",
      "2644    howard marks put -pron- nicely when -pron- say...\n",
      "710     mr klein currently serve as the executive vice...\n",
      "1247    semis be on fire the smh semiconductor etf hav...\n",
      "1979    the end to the u s government shutdown report ...\n",
      "2132    new york nov 04 2019 globe newswire halper sad...\n",
      "402     global medical device contract manufacturing m...\n",
      "2293    investor in scynexis inc scyx need to pay clos...\n",
      "2786    new york nov 01 2019 globe newswire acreage ho...\n",
      "2924    fall power line touch the ground on camino dia...\n",
      "1039    reuters warehouse giant prologis inc pld n say...\n",
      "3785    london dec 24 2018 globe newswire vivopower in...\n",
      "1304    investor look for stock in the building produc...\n",
      "1503    tempe ariz april 17 2019 prnewswire benchmark ...\n",
      "3031    gtt communications gtt come out with a quarter...\n",
      "                              ...                        \n",
      "1607    fourth quarter 2018 result revenue total 5 7 m...\n",
      "2913    the world s first bitcoin be mine ten year ago...\n",
      "2614    here s a roundup of top development in the bio...\n",
      "2528    omaha neb july 25 2019 prnewswire valmont util...\n",
      "2460    by john vandermosten cfa nasdaq vvus read the ...\n",
      "379     -pron- look like argo group international hold...\n",
      "124     check out the company make headline before the...\n",
      "1753    if -pron- want portfolio income dividend stock...\n",
      "2983    long term investing work well but -pron- doesn...\n",
      "919     tustin calif june 24 2019 globe newswire avid ...\n",
      "2014    dublin oct 25 2019 prnewswire the cable operat...\n",
      "3340    leiden netherlands and cambridge mass dec 10 2...\n",
      "2030    london nov 4 2019 prnewswire finastra today un...\n",
      "1537    selbyville delaware june 28 2019 globe newswir...\n",
      "3627    overland park kan business wire waddell reed f...\n",
      "706     san francisco july 16 2019 prnewswire hagens b...\n",
      "603     thomasville ga july 24 2019 flowers foods flo ...\n",
      "3599    applied materials amat close at 46 33 in the l...\n",
      "2532    armonk n y and ehningen germany oct 29 2019 pr...\n",
      "1038    a customer pass by an l brands inc victoria s ...\n",
      "183     reuters march 6 abercrombie fitch forecast ful...\n",
      "3762    san antonio aug 28 2019 globe newswire victory...\n",
      "1436    as the canadian cannabis market face an over s...\n",
      "284     ceo of altair engineering inc 30 year financia...\n",
      "2020    sacramento calif nov 4 2019 prnewswire dairy c...\n",
      "1659    los angeles reuters electricity be shut off to...\n",
      "1590    rutherford n j jan 28 2019 globe newswire canc...\n",
      "1230    check out the company make headline before the...\n",
      "840     quarterly revenue of 3 54 billion gaap and non...\n",
      "2998    want to participate in a short research study ...\n",
      "Name: CONTENT, Length: 3045, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mdvpty4pxEF0"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXS9fCdZxJ1g"
   },
   "outputs": [],
   "source": [
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRz3tfNGxO1p"
   },
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YrxqgZRExzHZ",
    "outputId": "53f1a2f0-488a-4edd-dde4-2d53febf408e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835420.71it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "Aselc0Fkx9ft",
    "outputId": "2cca6ea3-5648-4f8f-981d-3e49a1d5cf3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1394873.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2087407.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2087407.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392987.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2087904.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 596940.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 596615.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044387.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 696134.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2089647.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835141.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392766.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 834903.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2090146.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392434.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391549.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835341.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392212.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392655.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391660.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392434.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835460.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2090894.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835460.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044201.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391881.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2087158.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2088153.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391549.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2088402.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pjgemoGnyP2p",
    "outputId": "d6ea73e4-8e94-4d2a-ed90-1339320a48c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1375489.35it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "tth8c0iWyVlQ",
    "outputId": "f4792ba3-c571-4cde-89d4-0971da019c9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2086909.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044263.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392655.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044699.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044948.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391991.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1042523.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392766.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392323.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2091394.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391991.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1393652.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 836178.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1043703.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1393098.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392877.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 696051.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392323.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1393763.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044512.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1397209.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392323.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1391107.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2089398.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 835380.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1044699.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 2087158.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1392766.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1393763.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4177/4177 [00:00<00:00, 1043641.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "3A8vd8hkygf6",
    "outputId": "2fc9e751-7c37-4936-bb0d-8b0f3c51f1b0"
   },
   "outputs": [],
   "source": [
    "model_ug_cbow.save('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg.save('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARvQQXTQyx6-"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_ug_cbow = KeyedVectors.load('w2v_model_ug_cbow.word2vec')\n",
    "model_ug_sg = KeyedVectors.load('w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CbYfppZmy0AA",
    "outputId": "5c438739-839a-424f-8bbe-68117723bbb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_ug_cbow.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KY2zG8DazAXY",
    "outputId": "d1ec1169-1079-415d-c257-9b2a8d4c6134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33422 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_ug_cbow.wv.vocab.keys():\n",
    "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\manzh\\anaconda3\\lib\\site-packages (from keras) (1.17.3)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 568, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\users\\\\manzh\\\\anaconda3\\\\lib\\\\site-packages\\\\html5lib-1.0.1.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "tPrbFxIMzCD9",
    "outputId": "aef235af-52b3-409f-9d3c-a161aceb2412"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rno4m-VxzHAc",
    "outputId": "5d763d34-6e57-4fec-e6d3-2db030631229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42225"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "PSrlonYCzLSG",
    "outputId": "1e4a5d4c-804a-48d8-871f-4f2d1046d22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the stock market get hit with a double whammy on friday come from a glut of new public offering and a threat from the white house to limit u s investment in china cnbc s jim cramer say the mad money host say busted deal such as peloton smiledirectclub lyft and uber be happen too often and have contribute to a number of down day on wall street in the midst of an ongoing trade war between the world s large economy the public also learn during the day that trump administration official be look at way to deter u s company from invest in chinese company a move that cramer support turn out -pron- s not as sweeping or as negative as the market seem to believe -pron- say the administration doesn t want chinese listing that lack the same kind of transparency as american company and -pron- would prefer investor not to buy the share of company with opaque financial the dow jones industrial average lose more than 70 point or 0 26 while the s p 500 pull back 0 53 and the nasdaq composite drop 1 13 -pron- know -pron- s be rough but last week this market be really overbought still and when -pron- re overbought -pron- tend to get hit with sell off especially when -pron- re be flood with shoddy ipo merchandise cramer say -pron- think -pron- need some more downside before -pron- m really ready to get more positive cramer also give -pron- game plan for next week monday thor industries thor industries report earning before the market open shares of the recreational vehicle manufacturer have struggle as of late down nearly 70 from -pron- january 2018 all time high on the back of a series of earning miss cramer note that labor and raw cost on top of dim demand have contribute to woe in the camping cohort if there s ever go to be an upside surprise here -pron- s go to be this quarter because interest rate be finally go down for now though -pron- think -pron- s way too risky -pron- say thor need to deliver at least one quarter please of good number before -pron- have -pron- permission to circle back tuesday mccormick stitch fix mccormick present quarterly number before the open bell analyst be look for a profit of 1 29 per share on 1 3 billion revenue in the cramer fave spice maker the stock drop more than 2 in friday s session if -pron- keep fall on monday -pron- re go to get a good opportunity to buy this thing -pron- say mccormick be one of the few company in the supermarket that s get real growth stitch fix have an earning call after the close bell wall street expect 4 cent earning per share and 432 million of sale which would represent nearly 37 year over year growth share be down more than 42 since late june expensive valuation never seem to matter to the stock until june cramer say that s what happen though when -pron- go out of style on the wall street fashion show watch how this one behave after the quarter wednesday lennar bed bath beyond lennar deliver a quarterly report in the morning housing have be a strong spot in the economy and share of the homebuilder have be steadily grow close friday s session shy of 40 year to date housing s respond to low interest rate cramer say so if this stock get hit on the quarter call -pron- a buyer bed bath beyond s earning report come after the market close the company have be shake up by activist investor look to stabilize sale and cut cost at the home good retailer the stock be at 9 91 more than 2 high than -pron- august low bed bath finally look like -pron- s kind of bottom cramer say let s hear what -pron- have to say before -pron- try to pick at this one though thursday pepsico constellation brands costco pepsico report earning in the morning the stock be up more than 11 from early august -pron- think pepsico be exactly what work in this dicey environment cramer say -pron- m look for 5 organic growth constellation brands have a quarterly call before the bell constellation may help -pron- understand -pron- cannabis strategy not to mention please have something to say about spiked seltzer which be the hot part of the alcohol market -pron- say costco deliver earning after trading end the stock have fall about 17 in three week -pron- expect one more leg down before the stock s safe to buy the host say friday september job report employment s be strong but now everyone -pron- know be act like the good time stop roll cramer say -pron- don t think that s the case -pron- expect another good number which may make -pron- difficult for the fed to give -pron- another rate cut watch cramer s game plan\n"
     ]
    }
   ],
   "source": [
    "for x in x_train[:1]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TbPYmkTczO5I",
    "outputId": "4d818ae3-6e73-4482-c6f9-8e6b9ae2a94f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  34,\n",
       "  19,\n",
       "  195,\n",
       "  1294,\n",
       "  16,\n",
       "  8,\n",
       "  995,\n",
       "  10,\n",
       "  1184,\n",
       "  234,\n",
       "  21,\n",
       "  8,\n",
       "  3,\n",
       "  52,\n",
       "  402,\n",
       "  475,\n",
       "  2,\n",
       "  8,\n",
       "  2071,\n",
       "  21,\n",
       "  1,\n",
       "  2342,\n",
       "  915,\n",
       "  5,\n",
       "  808,\n",
       "  123,\n",
       "  12,\n",
       "  95,\n",
       "  7,\n",
       "  346,\n",
       "  1074,\n",
       "  12,\n",
       "  2320,\n",
       "  2120,\n",
       "  60,\n",
       "  1,\n",
       "  656,\n",
       "  1140,\n",
       "  60,\n",
       "  445,\n",
       "  118,\n",
       "  15,\n",
       "  1271,\n",
       "  2,\n",
       "  2546,\n",
       "  6,\n",
       "  1339,\n",
       "  980,\n",
       "  1111,\n",
       "  2,\n",
       "  13,\n",
       "  991,\n",
       "  5,\n",
       "  8,\n",
       "  242,\n",
       "  3,\n",
       "  216,\n",
       "  172,\n",
       "  10,\n",
       "  791,\n",
       "  814,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  37,\n",
       "  1207,\n",
       "  255,\n",
       "  1602,\n",
       "  391,\n",
       "  1,\n",
       "  272,\n",
       "  12,\n",
       "  212,\n",
       "  1025,\n",
       "  1,\n",
       "  402,\n",
       "  74,\n",
       "  896,\n",
       "  174,\n",
       "  1,\n",
       "  172,\n",
       "  11,\n",
       "  1212,\n",
       "  1112,\n",
       "  1802,\n",
       "  6,\n",
       "  45,\n",
       "  23,\n",
       "  519,\n",
       "  5,\n",
       "  123,\n",
       "  12,\n",
       "  18,\n",
       "  21,\n",
       "  545,\n",
       "  7,\n",
       "  1075,\n",
       "  18,\n",
       "  8,\n",
       "  358,\n",
       "  11,\n",
       "  2120,\n",
       "  373,\n",
       "  600,\n",
       "  203,\n",
       "  4,\n",
       "  12,\n",
       "  40,\n",
       "  15,\n",
       "  22,\n",
       "  15,\n",
       "  687,\n",
       "  15,\n",
       "  1,\n",
       "  19,\n",
       "  1414,\n",
       "  5,\n",
       "  249,\n",
       "  4,\n",
       "  60,\n",
       "  1,\n",
       "  1112,\n",
       "  1491,\n",
       "  148,\n",
       "  396,\n",
       "  1075,\n",
       "  2451,\n",
       "  11,\n",
       "  1623,\n",
       "  1,\n",
       "  312,\n",
       "  681,\n",
       "  3,\n",
       "  15,\n",
       "  695,\n",
       "  18,\n",
       "  2,\n",
       "  4,\n",
       "  144,\n",
       "  78,\n",
       "  40,\n",
       "  5,\n",
       "  179,\n",
       "  1,\n",
       "  31,\n",
       "  3,\n",
       "  18,\n",
       "  16,\n",
       "  66,\n",
       "  1,\n",
       "  1371,\n",
       "  2575,\n",
       "  332,\n",
       "  152,\n",
       "  892,\n",
       "  39,\n",
       "  84,\n",
       "  717,\n",
       "  253,\n",
       "  22,\n",
       "  32,\n",
       "  488,\n",
       "  182,\n",
       "  1,\n",
       "  12,\n",
       "  168,\n",
       "  425,\n",
       "  2510,\n",
       "  491,\n",
       "  32,\n",
       "  1076,\n",
       "  2,\n",
       "  1,\n",
       "  131,\n",
       "  2637,\n",
       "  1000,\n",
       "  14,\n",
       "  235,\n",
       "  4,\n",
       "  399,\n",
       "  4,\n",
       "  12,\n",
       "  6,\n",
       "  82,\n",
       "  140,\n",
       "  382,\n",
       "  25,\n",
       "  19,\n",
       "  6,\n",
       "  593,\n",
       "  555,\n",
       "  2,\n",
       "  208,\n",
       "  4,\n",
       "  171,\n",
       "  4,\n",
       "  2072,\n",
       "  5,\n",
       "  195,\n",
       "  1294,\n",
       "  16,\n",
       "  220,\n",
       "  403,\n",
       "  1434,\n",
       "  208,\n",
       "  4,\n",
       "  171,\n",
       "  6,\n",
       "  16,\n",
       "  1052,\n",
       "  2120,\n",
       "  60,\n",
       "  4,\n",
       "  188,\n",
       "  4,\n",
       "  334,\n",
       "  164,\n",
       "  39,\n",
       "  250,\n",
       "  4,\n",
       "  173,\n",
       "  593,\n",
       "  1764,\n",
       "  5,\n",
       "  195,\n",
       "  39,\n",
       "  348,\n",
       "  2120,\n",
       "  74,\n",
       "  306,\n",
       "  4,\n",
       "  1480,\n",
       "  181,\n",
       "  9,\n",
       "  241,\n",
       "  382,\n",
       "  1102,\n",
       "  1050,\n",
       "  1050,\n",
       "  44,\n",
       "  49,\n",
       "  250,\n",
       "  1,\n",
       "  19,\n",
       "  568,\n",
       "  1009,\n",
       "  3,\n",
       "  1,\n",
       "  441,\n",
       "  1031,\n",
       "  13,\n",
       "  2511,\n",
       "  15,\n",
       "  3,\n",
       "  327,\n",
       "  216,\n",
       "  788,\n",
       "  717,\n",
       "  21,\n",
       "  4,\n",
       "  907,\n",
       "  42,\n",
       "  94,\n",
       "  99,\n",
       "  79,\n",
       "  10,\n",
       "  1,\n",
       "  491,\n",
       "  3,\n",
       "  8,\n",
       "  1392,\n",
       "  3,\n",
       "  49,\n",
       "  967,\n",
       "  2120,\n",
       "  384,\n",
       "  11,\n",
       "  1908,\n",
       "  2,\n",
       "  2293,\n",
       "  91,\n",
       "  10,\n",
       "  262,\n",
       "  3,\n",
       "  278,\n",
       "  13,\n",
       "  991,\n",
       "  5,\n",
       "  7,\n",
       "  1,\n",
       "  143,\n",
       "  136,\n",
       "  12,\n",
       "  1728,\n",
       "  155,\n",
       "  5,\n",
       "  6,\n",
       "  37,\n",
       "  1781,\n",
       "  559,\n",
       "  268,\n",
       "  4,\n",
       "  12,\n",
       "  155,\n",
       "  5,\n",
       "  6,\n",
       "  25,\n",
       "  30,\n",
       "  232,\n",
       "  154,\n",
       "  150,\n",
       "  6,\n",
       "  1849,\n",
       "  155,\n",
       "  216,\n",
       "  9,\n",
       "  196,\n",
       "  1298,\n",
       "  4,\n",
       "  188,\n",
       "  4,\n",
       "  12,\n",
       "  519,\n",
       "  980,\n",
       "  4,\n",
       "  60,\n",
       "  334,\n",
       "  5,\n",
       "  360,\n",
       "  23,\n",
       "  985,\n",
       "  124,\n",
       "  30,\n",
       "  336,\n",
       "  3,\n",
       "  114,\n",
       "  242,\n",
       "  250,\n",
       "  4,\n",
       "  13,\n",
       "  4,\n",
       "  5,\n",
       "  491,\n",
       "  1089,\n",
       "  1224,\n",
       "  476,\n",
       "  468,\n",
       "  242,\n",
       "  250,\n",
       "  1,\n",
       "  568,\n",
       "  2054,\n",
       "  151,\n",
       "  6,\n",
       "  45,\n",
       "  9,\n",
       "  8,\n",
       "  506,\n",
       "  3,\n",
       "  14,\n",
       "  455,\n",
       "  63,\n",
       "  31,\n",
       "  10,\n",
       "  14,\n",
       "  29,\n",
       "  121,\n",
       "  55,\n",
       "  7,\n",
       "  1,\n",
       "  2120,\n",
       "  1401,\n",
       "  1,\n",
       "  34,\n",
       "  1000,\n",
       "  39,\n",
       "  84,\n",
       "  24,\n",
       "  7,\n",
       "  1184,\n",
       "  12,\n",
       "  1312,\n",
       "  143,\n",
       "  4,\n",
       "  739,\n",
       "  541,\n",
       "  10,\n",
       "  1102,\n",
       "  4,\n",
       "  171,\n",
       "  155,\n",
       "  5,\n",
       "  195,\n",
       "  8,\n",
       "  114,\n",
       "  301,\n",
       "  5,\n",
       "  179,\n",
       "  25,\n",
       "  605,\n",
       "  4,\n",
       "  60,\n",
       "  6,\n",
       "  124,\n",
       "  3,\n",
       "  1,\n",
       "  700,\n",
       "  18,\n",
       "  7,\n",
       "  1,\n",
       "  11,\n",
       "  12,\n",
       "  195,\n",
       "  483,\n",
       "  57,\n",
       "  1224,\n",
       "  13,\n",
       "  37,\n",
       "  49,\n",
       "  122,\n",
       "  184,\n",
       "  1,\n",
       "  349,\n",
       "  2054,\n",
       "  791,\n",
       "  814,\n",
       "  67,\n",
       "  36,\n",
       "  561,\n",
       "  49,\n",
       "  63,\n",
       "  31,\n",
       "  2,\n",
       "  27,\n",
       "  3,\n",
       "  89,\n",
       "  46,\n",
       "  144,\n",
       "  330,\n",
       "  788,\n",
       "  756,\n",
       "  26,\n",
       "  59,\n",
       "  26,\n",
       "  57,\n",
       "  31,\n",
       "  6,\n",
       "  216,\n",
       "  39,\n",
       "  84,\n",
       "  782,\n",
       "  308,\n",
       "  327,\n",
       "  199,\n",
       "  1164,\n",
       "  2263,\n",
       "  1414,\n",
       "  5,\n",
       "  724,\n",
       "  5,\n",
       "  1,\n",
       "  34,\n",
       "  971,\n",
       "  199,\n",
       "  2120,\n",
       "  60,\n",
       "  11,\n",
       "  12,\n",
       "  166,\n",
       "  1339,\n",
       "  1298,\n",
       "  208,\n",
       "  4,\n",
       "  155,\n",
       "  203,\n",
       "  3,\n",
       "  1813,\n",
       "  10,\n",
       "  1,\n",
       "  791,\n",
       "  814,\n",
       "  2527,\n",
       "  310,\n",
       "  1181,\n",
       "  236,\n",
       "  25,\n",
       "  124,\n",
       "  184,\n",
       "  1,\n",
       "  30,\n",
       "  869,\n",
       "  2689,\n",
       "  921,\n",
       "  360,\n",
       "  8,\n",
       "  468,\n",
       "  44,\n",
       "  7,\n",
       "  1,\n",
       "  1290,\n",
       "  1765,\n",
       "  13,\n",
       "  6,\n",
       "  8,\n",
       "  202,\n",
       "  1358,\n",
       "  7,\n",
       "  1,\n",
       "  1025,\n",
       "  2,\n",
       "  31,\n",
       "  3,\n",
       "  1,\n",
       "  13,\n",
       "  6,\n",
       "  198,\n",
       "  349,\n",
       "  1184,\n",
       "  12,\n",
       "  1312,\n",
       "  3,\n",
       "  472,\n",
       "  26,\n",
       "  5,\n",
       "  252,\n",
       "  1765,\n",
       "  12,\n",
       "  1951,\n",
       "  5,\n",
       "  183,\n",
       "  154,\n",
       "  150,\n",
       "  2120,\n",
       "  60,\n",
       "  97,\n",
       "  143,\n",
       "  25,\n",
       "  34,\n",
       "  195,\n",
       "  1294,\n",
       "  10,\n",
       "  1,\n",
       "  30,\n",
       "  122,\n",
       "  4,\n",
       "  8,\n",
       "  2024,\n",
       "  2689,\n",
       "  921,\n",
       "  12,\n",
       "  49,\n",
       "  44,\n",
       "  234,\n",
       "  184,\n",
       "  1,\n",
       "  19,\n",
       "  349,\n",
       "  1,\n",
       "  18,\n",
       "  13,\n",
       "  6,\n",
       "  81,\n",
       "  17,\n",
       "  78,\n",
       "  45,\n",
       "  5,\n",
       "  89,\n",
       "  2,\n",
       "  707,\n",
       "  91,\n",
       "  23,\n",
       "  1,\n",
       "  430,\n",
       "  114,\n",
       "  1196,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  23,\n",
       "  73,\n",
       "  1546,\n",
       "  39,\n",
       "  84,\n",
       "  24,\n",
       "  79,\n",
       "  84,\n",
       "  4,\n",
       "  682,\n",
       "  183,\n",
       "  2689,\n",
       "  1849,\n",
       "  45,\n",
       "  211,\n",
       "  4,\n",
       "  12,\n",
       "  681,\n",
       "  3,\n",
       "  1024,\n",
       "  2120,\n",
       "  60,\n",
       "  958,\n",
       "  12,\n",
       "  2471,\n",
       "  166,\n",
       "  4,\n",
       "  13,\n",
       "  5,\n",
       "  60,\n",
       "  250,\n",
       "  4,\n",
       "  1027,\n",
       "  5,\n",
       "  792,\n",
       "  23,\n",
       "  25,\n",
       "  124,\n",
       "  1298,\n",
       "  848,\n",
       "  831,\n",
       "  44,\n",
       "  49,\n",
       "  7,\n",
       "  1,\n",
       "  1290,\n",
       "  1,\n",
       "  34,\n",
       "  6,\n",
       "  81,\n",
       "  39,\n",
       "  84,\n",
       "  162,\n",
       "  21,\n",
       "  490,\n",
       "  682,\n",
       "  4,\n",
       "  188,\n",
       "  6,\n",
       "  166,\n",
       "  264,\n",
       "  7,\n",
       "  25,\n",
       "  793,\n",
       "  2120,\n",
       "  60,\n",
       "  4,\n",
       "  173,\n",
       "  45,\n",
       "  9,\n",
       "  35,\n",
       "  963,\n",
       "  57,\n",
       "  831,\n",
       "  13,\n",
       "  8,\n",
       "  468,\n",
       "  122,\n",
       "  250,\n",
       "  1,\n",
       "  2054,\n",
       "  61,\n",
       "  298,\n",
       "  4,\n",
       "  1113,\n",
       "  4,\n",
       "  832,\n",
       "  282,\n",
       "  40,\n",
       "  5,\n",
       "  800,\n",
       "  336,\n",
       "  13,\n",
       "  1603,\n",
       "  5,\n",
       "  60,\n",
       "  58,\n",
       "  46,\n",
       "  6,\n",
       "  1,\n",
       "  2818,\n",
       "  374,\n",
       "  3,\n",
       "  1,\n",
       "  19,\n",
       "  4,\n",
       "  60,\n",
       "  360,\n",
       "  49,\n",
       "  184,\n",
       "  594,\n",
       "  70,\n",
       "  1,\n",
       "  34,\n",
       "  13,\n",
       "  541,\n",
       "  58,\n",
       "  309,\n",
       "  7,\n",
       "  159,\n",
       "  382,\n",
       "  4,\n",
       "  67,\n",
       "  124,\n",
       "  39,\n",
       "  216,\n",
       "  250,\n",
       "  1,\n",
       "  34,\n",
       "  12,\n",
       "  1053,\n",
       "  5,\n",
       "  179,\n",
       "  1,\n",
       "  1140,\n",
       "  60,\n",
       "  1184,\n",
       "  297,\n",
       "  1274,\n",
       "  44,\n",
       "  12,\n",
       "  6,\n",
       "  202,\n",
       "  82,\n",
       "  196,\n",
       "  1586,\n",
       "  4,\n",
       "  399,\n",
       "  6,\n",
       "  426,\n",
       "  211,\n",
       "  1,\n",
       "  114,\n",
       "  99,\n",
       "  2420,\n",
       "  1952,\n",
       "  2120,\n",
       "  60,\n",
       "  4,\n",
       "  749,\n",
       "  148,\n",
       "  188,\n",
       "  11,\n",
       "  12,\n",
       "  1,\n",
       "  633,\n",
       "  4,\n",
       "  67,\n",
       "  811,\n",
       "  114,\n",
       "  242,\n",
       "  46,\n",
       "  61,\n",
       "  102,\n",
       "  4,\n",
       "  1295,\n",
       "  9,\n",
       "  1,\n",
       "  1983,\n",
       "  5,\n",
       "  306,\n",
       "  4,\n",
       "  811,\n",
       "  150,\n",
       "  707,\n",
       "  1181,\n",
       "  2120,\n",
       "  12,\n",
       "  1480,\n",
       "  181]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPcpdjHizSW3"
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DW5D9SpEzWIF",
    "outputId": "fa3a3101-1bff-4180-b617-6277ac6862a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14743"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rukb8Td2za6q",
    "outputId": "4a7e0428-eba5-4551-aa42-58864790c239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (3045, 15000)\n"
     ]
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=15000)\n",
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "89xZ7y9wzm0g",
    "outputId": "47aa88ff-f1c5-4005-d6aa-2061b869a72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   12, 1480,  181]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-mHax410GJ8"
   },
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49yolVys0Mke"
   },
   "outputs": [],
   "source": [
    "num_words = 3000\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**I am defining the number of words to be 3000. This means I will only care about 3000 most frequent words in the training set, which has 3045 datapoints. If I don’t limit the number of words, the total number of vocabulary will be more than 40000.**#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DrUpANng0Sxu",
    "outputId": "68e13c85-f2c3-4e76-82d4-155af7b7b22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(embedding_matrix[34] ,embeddings_index.get('stock'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fg9c0aCv0zOd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\manzh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "KbPDHAwG062h",
    "outputId": "98dea5fe-3f5c-4e2e-f145-d9e6f8c6b843"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-518a5375d70c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_ptw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_ptw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_ptw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_ptw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "model_ptw2v = Sequential()\n",
    "e = Embedding(3000, 200, weights=[embedding_matrix], input_length=15000, trainable=False)\n",
    "model_ptw2v.add(e)\n",
    "model_ptw2v.add(Flatten())\n",
    "model_ptw2v.add(Dense(256, activation='relu'))\n",
    "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
    "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ACWvd9m-0_NO",
    "outputId": "de2c2870-2153-406f-c41c-18ece0f027dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3045 samples, validate on 762 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model_ptw2v = Sequential()\n",
    "e = Embedding(3000, 200, input_length=15000)\n",
    "model_ptw2v.add(e)\n",
    "model_ptw2v.add(Flatten())\n",
    "model_ptw2v.add(Dense(256, activation='relu'))\n",
    "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
    "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxUeLVbp1N6g"
   },
   "outputs": [],
   "source": [
    "model_ptw2v = Sequential()\n",
    "e = Embedding(3000, 200, weights=[embedding_matrix], input_length=15000, trainable=True)\n",
    "model_ptw2v.add(e)\n",
    "model_ptw2v.add(Flatten())\n",
    "model_ptw2v.add(Dense(256, activation='relu'))\n",
    "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
    "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9StW1031W0f"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UuxvhKD1kJX"
   },
   "outputs": [],
   "source": [
    "structure_test = Sequential()\n",
    "e = Embedding(3000, 200, input_length=15000)\n",
    "structure_test.add(e)\n",
    "structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "structure_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfoyTYQa1qEY"
   },
   "outputs": [],
   "source": [
    "structure_test = Sequential()\n",
    "e = Embedding(3000, 200, input_length=15000)\n",
    "structure_test.add(e)\n",
    "structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "structure_test.add(GlobalMaxPooling1D())\n",
    "structure_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOgsIYlV1wRT"
   },
   "outputs": [],
   "source": [
    "model_cnn_01 = Sequential()\n",
    "e = Embedding(3000, 200, weights=[embedding_matrix], input_length=15000, trainable=False)\n",
    "model_cnn_01.add(e)\n",
    "model_cnn_01.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_01.add(GlobalMaxPooling1D())\n",
    "model_cnn_01.add(Dense(256, activation='relu'))\n",
    "model_cnn_01.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_01.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tml97KJK11m1"
   },
   "outputs": [],
   "source": [
    "model_cnn_02 = Sequential()\n",
    "e = Embedding(3000, 200, input_length=15000)\n",
    "model_cnn_02.add(e)\n",
    "model_cnn_02.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_02.add(GlobalMaxPooling1D())\n",
    "model_cnn_02.add(Dense(256, activation='relu'))\n",
    "model_cnn_02.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn_02.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EYXRnuI159C"
   },
   "outputs": [],
   "source": [
    "model_cnn_03 = Sequential()\n",
    "e = Embedding(3000, 200, weights=[embedding_matrix], input_length=15000, trainable=True)\n",
    "model_cnn_03.add(e)\n",
    "model_cnn_03.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_03.add(GlobalMaxPooling1D())\n",
    "model_cnn_03.add(Dense(256, activation='relu'))\n",
    "model_cnn_03.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_cnn_03.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJ_FY-TB1_-c"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_input = Input(shape=(15000,), dtype='int32')\n",
    "\n",
    "tweet_encoder = Embedding(3000, 200, weights=[embedding_matrix], input_length=15000, trainable=True)(tweet_input)\n",
    "bigram_branch = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
    "trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
    "fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
    "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
    "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
    "\n",
    "merged = Dense(256, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "merged = Dense(1)(merged)\n",
    "output = Activation('sigmoid')(merged)\n",
    "model = Model(inputs=[tweet_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOA867Da2Nzs"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"CNN_best_weights.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(x_train_seq, y_train, batch_size=32, epochs=5,\n",
    "                     validation_data=(x_val_seq, y_validation), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNbndWC02Vak"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_CNN_model = load_model('CNN_best_weights.02-0.8333.hdf5')\n",
    "loaded_CNN_model.evaluate(x=x_val_seq, y=y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EBmuh9_2_0O"
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjVGniM13RTb"
   },
   "outputs": [],
   "source": [
    "loaded_CNN_model.evaluate(x=x_test_seq, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_dm4UpY3Zi-"
   },
   "outputs": [],
   "source": [
    "yhat_cnn = loaded_CNN_model.predict(x_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88bB-GDj3ajx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, threshold = roc_curve(y_test, yhat_lr[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fpr_cnn, tpr_cnn, threshold = roc_curve(y_test, yhat_cnn)\n",
    "roc_auc_nn = auc(fpr_cnn, tpr_cnn)\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.plot(fpr, tpr, label='tfidf-logit (area = %0.3f)' % roc_auc, linewidth=2)\n",
    "plt.plot(fpr_cnn, tpr_cnn, label='w2v-CNN (area = %0.3f)' % roc_auc_nn, linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic: is positive', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CS_SA_CNN&W2V.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
